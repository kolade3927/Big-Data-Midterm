{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions\n",
    "\n",
    "For this midterm you will be performing an analysis on a document that has been converted using a\n",
    "Caesar Cypher.\n",
    "\n",
    "To do this you will do the following:\n",
    "\n",
    "- Word Count of the document\n",
    "- Character Count of the document\n",
    "- Comparison to the expected frequencies of characters in the English Language\n",
    "- Use a natural language processing library to compare samples of the words within your\n",
    "document to see if they are valid english words\n",
    "- Find the correct decryption of the document and save the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row, functions as sql_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-6UG11SJ0:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>digits-recognition</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a17a17b5c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up environment configurations\n",
    "conf = SparkConf().setAppName('digits-recognition')\n",
    "conf.set('spark.executor.memory', '12g') # 12 Gigabytes of RAM memory\n",
    "\n",
    "# Create a spark SQL session, or get if already existing (only one instance)\n",
    "sess = SparkSession.builder.config(conf = conf).getOrCreate()\n",
    "\n",
    "# Reduce the verbose log\n",
    "#sess.sparkContext.setLogLevel(\"WARN\")\n",
    "sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the text file, and cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'Encrypted-1.txt'\n",
    "df = sess.read.text(filename)\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|CNEGVPHYNE CREVBQ...|\n",
      "|1988; OHG GURER N...|\n",
      "|_________________...|\n",
      "|                    |\n",
      "|ABQR:AC-, ARKG:[9...|\n",
      "|                    |\n",
      "|     AC- /A-C/ CERS.|\n",
      "|                    |\n",
      "|RKGERZRYL. HFRQ G...|\n",
      "|QVSSVPHYGL; GUR P...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 2000\n"
     ]
    }
   ],
   "source": [
    "print('Total lines:', df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Dataframe to RDD\n",
    "rdd = df.rdd.map(lambda row: row.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word and Character Counts of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    punctuations = string.punctuation\n",
    "    trans = str.maketrans('', '', punctuations)\n",
    "    \n",
    "    return text.translate(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_characters(text, remove_num=True):\n",
    "    # Remove spaces\n",
    "    text = text.replace(' ', '')\n",
    "    \n",
    "    # Split into characters\n",
    "    chars = list(text)\n",
    "    \n",
    "    if remove_num:\n",
    "        # Remove numerical characters\n",
    "        chars = [c for c in chars if c.isalpha()]\n",
    "    \n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entities(rdd, level='word', remove_punc=True):\n",
    "    if remove_punc:\n",
    "        # Remove punctuations\n",
    "        rdd = rdd.map(remove_punctuations)\n",
    "        print('\\nAfter removing punctuations:')\n",
    "        print( rdd.take(5) )\n",
    "    \n",
    "    # Split text into entities\n",
    "    if level == 'word':\n",
    "        rdd_entities = rdd.flatMap(lambda line: line.split(' ') )\n",
    "    else:\n",
    "        rdd_entities = rdd.flatMap(split_characters)\n",
    "        \n",
    "    print('\\nAfter spliting into entities:')\n",
    "    print( rdd_entities.take(5) )\n",
    "    \n",
    "    # Prepare each entity for counting\n",
    "    rdd_entities_once = rdd_entities.map(lambda entity: (entity, 1))\n",
    "    print('\\nEach time an entity occurs:')\n",
    "    print( rdd_entities_once.take(5) )\n",
    "    \n",
    "    # Aggregate count all the entities occurences\n",
    "    rdd_entity_counts = rdd_entities_once.reduceByKey(add)\n",
    "    print('\\nEntity counts:')\n",
    "    print( rdd_entity_counts.take(5) )\n",
    "    \n",
    "    return rdd_entity_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing punctuations:\n",
      "['CNEGVPHYNE CREVBQ BS SYNXVARFF BA VOZF IARG PBECBENGR ARGJBEX PN', '1988 OHG GURER NER VAQRCRAQRAG ERCBEGF BS GUR GREZ SEBZ RYFRJURER', '', '', 'ABQRAC ARKG9529AEBSS CERIVBHF9530ABGJBEX HC9531 A ']\n",
      "\n",
      "After spliting into entities:\n",
      "['CNEGVPHYNE', 'CREVBQ', 'BS', 'SYNXVARFF', 'BA']\n",
      "\n",
      "Each time an entity occurs:\n",
      "[('CNEGVPHYNE', 1), ('CREVBQ', 1), ('BS', 1), ('SYNXVARFF', 1), ('BA', 1)]\n",
      "\n",
      "Entity counts:\n",
      "[('CNEGVPHYNE', 5), ('CREVBQ', 2), ('BS', 282), ('SYNXVARFF', 1), ('BA', 79)]\n"
     ]
    }
   ],
   "source": [
    "rdd_word_counts = count_entities(rdd, level='word', remove_punc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing punctuations:\n",
      "['CNEGVPHYNE CREVBQ BS SYNXVARFF BA VOZF IARG PBECBENGR ARGJBEX PN', '1988 OHG GURER NER VAQRCRAQRAG ERCBEGF BS GUR GREZ SEBZ RYFRJURER', '', '', 'ABQRAC ARKG9529AEBSS CERIVBHF9530ABGJBEX HC9531 A ']\n",
      "\n",
      "After spliting into entities:\n",
      "['C', 'N', 'E', 'G', 'V']\n",
      "\n",
      "Each time an entity occurs:\n",
      "[('C', 1), ('N', 1), ('E', 1), ('G', 1), ('V', 1)]\n",
      "\n",
      "Entity counts:\n",
      "[('C', 2135), ('N', 4143), ('E', 3454), ('G', 4451), ('V', 3569)]\n"
     ]
    }
   ],
   "source": [
    "rdd_char_counts = count_entities(rdd, level='character', remove_punc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expecting maximum of 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 26\n"
     ]
    }
   ],
   "source": [
    "print('Number of characters:', rdd_char_counts.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in the text: 53005\n"
     ]
    }
   ],
   "source": [
    "total_chars = rdd_char_counts.map(lambda c: c[1]).sum()\n",
    "print('Total characters in the text:', total_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_freq(char, total):\n",
    "    rel_freq = 100* (char[1] / total)\n",
    "    \n",
    "    return char[0], round(rel_freq, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Character Relative Frequencies:\n",
      "[('A', 7.28), ('B', 8.3), ('C', 4.03), ('D', 0.11), ('E', 6.52), ('F', 6.69), ('G', 8.4), ('H', 3.06), ('I', 1.06), ('J', 1.23), ('K', 0.54), ('L', 1.71), ('M', 0.11), ('N', 7.82), ('O', 1.72), ('P', 3.61), ('Q', 3.32), ('R', 12.01), ('S', 2.03), ('T', 2.07), ('U', 3.89), ('V', 6.73), ('W', 0.14), ('X', 0.8), ('Y', 3.95), ('Z', 2.87)]\n"
     ]
    }
   ],
   "source": [
    "rdd_rel_freq = rdd_char_counts.map(lambda char: rel_freq(char, total_chars) )\n",
    "rdd_rel_freq = rdd_rel_freq.sortByKey()\n",
    "\n",
    "print('Text Character Relative Frequencies:')\n",
    "print( rdd_rel_freq.collect() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to the expected frequencies of characters in the English Language\n",
    "\n",
    "Load the Letter frequency from Wikipedia [src: https://en.wikipedia.org/wiki/Letter_frequency ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['Letter', 'English', 'French', 'German', 'Spanish', 'Portuguese', 'Esperanto', 'Italian', 'Turkish', 'Swedish', 'Polish', 'Dutch', 'Danish', 'Icelandic', 'Finnish', 'Czech']\n",
      "+------+-------+\n",
      "|Letter|English|\n",
      "+------+-------+\n",
      "|     a| 8.167%|\n",
      "|     b| 1.492%|\n",
      "|     c| 2.782%|\n",
      "|     d| 4.253%|\n",
      "|     e|12.702%|\n",
      "|     f| 2.228%|\n",
      "|     g| 2.015%|\n",
      "|     h| 6.094%|\n",
      "|     i| 6.966%|\n",
      "|     j| 0.153%|\n",
      "|     k| 0.772%|\n",
      "|     l| 4.025%|\n",
      "|     m| 2.406%|\n",
      "|     n| 6.749%|\n",
      "|     o| 7.507%|\n",
      "|     p| 1.929%|\n",
      "|     q| 0.095%|\n",
      "|     r| 5.987%|\n",
      "|     s| 6.327%|\n",
      "|     t| 9.056%|\n",
      "+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "character_freq_filename = 'character_frequencies.txt'\n",
    "df_char_freq = sess.read.csv(character_freq_filename,\n",
    "                              header=True,\n",
    "                              sep='\\t')\n",
    "\n",
    "print('Columns:', df_char_freq.columns)\n",
    "df_char_freq.select('Letter', 'English').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df to rdd\n",
    "rdd_char_freq = df_char_freq.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_freq(val):\n",
    "    val = val.replace('%', '')\n",
    "    return float(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected English Character Frequencies:\n",
      "[('A', 8.167), ('B', 1.492), ('C', 2.782), ('D', 4.253), ('E', 12.702), ('F', 2.228), ('G', 2.015), ('H', 6.094), ('I', 6.966), ('J', 0.153), ('K', 0.772), ('L', 4.025), ('M', 2.406), ('N', 6.749), ('O', 7.507), ('P', 1.929), ('Q', 0.095), ('R', 5.987), ('S', 6.327), ('T', 9.056), ('U', 2.758), ('V', 0.978), ('W', 2.36), ('X', 0.15), ('Y', 1.974), ('Z', 0.074)]\n"
     ]
    }
   ],
   "source": [
    "# Extract the English character values\n",
    "rdd_en_char_freq = rdd_char_freq.map(lambda row: (row.Letter.upper(), parse_freq(row.English)))\n",
    "\n",
    "print('Expected English Character Frequencies:')\n",
    "print( rdd_en_char_freq.collect() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character frequencies summary:\n",
      "[Row(expected=2.782, found=2.782, letter='C'), Row(expected=0.153, found=0.153, letter='J'), Row(expected=0.772, found=0.772, letter='K'), Row(expected=4.025, found=4.025, letter='L'), Row(expected=6.749, found=6.749, letter='N'), Row(expected=7.507, found=7.507, letter='O'), Row(expected=5.987, found=5.987, letter='R'), Row(expected=6.327, found=6.327, letter='S'), Row(expected=2.36, found=2.36, letter='W'), Row(expected=8.167, found=8.167, letter='A'), Row(expected=1.492, found=1.492, letter='B'), Row(expected=4.253, found=4.253, letter='D'), Row(expected=12.702, found=12.702, letter='E'), Row(expected=2.228, found=2.228, letter='F'), Row(expected=2.015, found=2.015, letter='G'), Row(expected=6.094, found=6.094, letter='H'), Row(expected=6.966, found=6.966, letter='I'), Row(expected=2.406, found=2.406, letter='M'), Row(expected=1.929, found=1.929, letter='P'), Row(expected=0.095, found=0.095, letter='Q'), Row(expected=9.056, found=9.056, letter='T'), Row(expected=2.758, found=2.758, letter='U'), Row(expected=0.978, found=0.978, letter='V'), Row(expected=0.15, found=0.15, letter='X'), Row(expected=1.974, found=1.974, letter='Y'), Row(expected=0.074, found=0.074, letter='Z')]\n"
     ]
    }
   ],
   "source": [
    "rdd_comparison = rdd_en_char_freq.join(rdd_rel_freq)\n",
    "rdd_comparison = rdd_comparison.map(lambda r: Row(letter=r[0],\n",
    "                                                  expected=r[1][0],\n",
    "                                                  found=r[1][0]\n",
    "                                                 ))\n",
    "\n",
    "print('Character frequencies summary:')\n",
    "print(rdd_comparison.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+\n",
      "|letter|expected| found|\n",
      "+------+--------+------+\n",
      "|     C|   2.782| 2.782|\n",
      "|     J|   0.153| 0.153|\n",
      "|     K|   0.772| 0.772|\n",
      "|     L|   4.025| 4.025|\n",
      "|     N|   6.749| 6.749|\n",
      "|     O|   7.507| 7.507|\n",
      "|     R|   5.987| 5.987|\n",
      "|     S|   6.327| 6.327|\n",
      "|     W|    2.36|  2.36|\n",
      "|     A|   8.167| 8.167|\n",
      "|     B|   1.492| 1.492|\n",
      "|     D|   4.253| 4.253|\n",
      "|     E|  12.702|12.702|\n",
      "|     F|   2.228| 2.228|\n",
      "|     G|   2.015| 2.015|\n",
      "|     H|   6.094| 6.094|\n",
      "|     I|   6.966| 6.966|\n",
      "|     M|   2.406| 2.406|\n",
      "|     P|   1.929| 1.929|\n",
      "|     Q|   0.095| 0.095|\n",
      "+------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd_comparison.toDF().select('letter', 'expected', 'found').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a natural language processing library to compare samples of the words within your document to see if they are valid english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words = set( words.words() )\n",
    "\n",
    "def is_english_word(word):\n",
    "    return word.lower() in english_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_english_words(rdd):\n",
    "    # Tokenize \n",
    "    rdd_clean = rdd.map(remove_punctuations)\n",
    "    rdd_tokens = rdd_clean.flatMap(word_tokenize)\n",
    "    print('\\nTokenized words:')\n",
    "    print( rdd_tokens.take(10) )\n",
    "    \n",
    "    # Check for English words\n",
    "    rdd_english_tokens = rdd_tokens.map(lambda token: (token, is_english_word(token)) )\n",
    "    print('\\nEnglish words validation:')\n",
    "    print( rdd_english_tokens.take(10) )\n",
    "    \n",
    "    return rdd_english_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take some samples to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text:\n",
      "[\"CNEGVPHYNE CREVBQ BS SYNXVARFF BA VOZ'F IARG PBECBENGR ARGJBEX PN.\", '1988; OHG GURER NER VAQRCRAQRAG ERCBEGF BS GUR GREZ SEBZ RYFRJURER.', '_________________________________________________________________', '', 'ABQR:AC-, ARKG:[9529]AEBSS, CERIVBHF:[9530]ABGJBEX, HC:[9531]= A =']\n"
     ]
    }
   ],
   "source": [
    "n_samples = 5\n",
    "rdd_sample = df.limit(n_samples).rdd.map(lambda row: row.value)\n",
    "\n",
    "print('Sample text:')\n",
    "print( rdd_sample.collect() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized words:\n",
      "['CNEGVPHYNE', 'CREVBQ', 'BS', 'SYNXVARFF', 'BA', 'VOZF', 'IARG', 'PBECBENGR', 'ARGJBEX', 'PN']\n",
      "\n",
      "English words validation:\n",
      "[('CNEGVPHYNE', False), ('CREVBQ', False), ('BS', False), ('SYNXVARFF', False), ('BA', True), ('VOZF', False), ('IARG', False), ('PBECBENGR', False), ('ARGJBEX', False), ('PN', False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[91] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_english_words(rdd_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are not english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the correct decryption of the document and save the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = string.ascii_uppercase\n",
    "\n",
    "def decrypt(text, shift):\n",
    "    decrypted_text = ''\n",
    "    \n",
    "    for ch in text:\n",
    "        if ch.isalpha():\n",
    "            index = (letters.index(ch) - shift) % 26\n",
    "            decrypted_text += letters[index]\n",
    "        else:\n",
    "            decrypted_text += ch\n",
    "            \n",
    "    return decrypted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QEB NRFZH YOLTK CLU GRJMP LSBO QEB IXWV ALD deciphered to: THE QUICK BROWN FOX JUMPS OVER THE LAZY DOG\n"
     ]
    }
   ],
   "source": [
    "## Testing the decrypt function\n",
    "cipher = 'QEB NRFZH YOLTK CLU GRJMP LSBO QEB IXWV ALD'\n",
    "print(cipher, 'deciphered to:', decrypt(cipher, 23))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for the optimal shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decryption with shift: 0\n",
      "[\"CNEGVPHYNE CREVBQ BS SYNXVARFF BA VOZ'F IARG PBECBENGR ARGJBEX PN.\", '1988; OHG GURER NER VAQRCRAQRAG ERCBEGF BS GUR GREZ SEBZ RYFRJURER.', '_________________________________________________________________', '', 'ABQR:AC-, ARKG:[9529]AEBSS, CERIVBHF:[9530]ABGJBEX, HC:[9531]= A =']\n",
      "\n",
      "Tokenized words:\n",
      "['CNEGVPHYNE', 'CREVBQ', 'BS', 'SYNXVARFF', 'BA', 'VOZF', 'IARG', 'PBECBENGR', 'ARGJBEX', 'PN']\n",
      "\n",
      "English words validation:\n",
      "[('CNEGVPHYNE', False), ('CREVBQ', False), ('BS', False), ('SYNXVARFF', False), ('BA', True), ('VOZF', False), ('IARG', False), ('PBECBENGR', False), ('ARGJBEX', False), ('PN', False)]\n",
      "Fractional valid English word: 0.11538461538461539\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 1\n",
      "[\"BMDFUOGXMD BQDUAP AR RXMWUZQEE AZ UNY'E HZQF OADBADMFQ ZQFIADW OM.\", '1988; NGF FTQDQ MDQ UZPQBQZPQZF DQBADFE AR FTQ FQDY RDAY QXEQITQDQ.', '_________________________________________________________________', '', 'ZAPQ:ZB-, ZQJF:[9529]ZDARR, BDQHUAGE:[9530]ZAFIADW, GB:[9531]= Z =']\n",
      "\n",
      "Tokenized words:\n",
      "['BMDFUOGXMD', 'BQDUAP', 'AR', 'RXMWUZQEE', 'AZ', 'UNYE', 'HZQF', 'OADBADMFQ', 'ZQFIADW', 'OM']\n",
      "\n",
      "English words validation:\n",
      "[('BMDFUOGXMD', False), ('BQDUAP', False), ('AR', True), ('RXMWUZQEE', False), ('AZ', False), ('UNYE', False), ('HZQF', False), ('OADBADMFQ', False), ('ZQFIADW', False), ('OM', True)]\n",
      "Fractional valid English word: 0.15384615384615385\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 2\n",
      "[\"ALCETNFWLC APCTZO ZQ QWLVTYPDD ZY TMX'D GYPE NZCAZCLEP YPEHZCV NL.\", '1988; MFE ESPCP LCP TYOPAPYOPYE CPAZCED ZQ ESP EPCX QCZX PWDPHSPCP.', '_________________________________________________________________', '', 'YZOP:YA-, YPIE:[9529]YCZQQ, ACPGTZFD:[9530]YZEHZCV, FA:[9531]= Y =']\n",
      "\n",
      "Tokenized words:\n",
      "['ALCETNFWLC', 'APCTZO', 'ZQ', 'QWLVTYPDD', 'ZY', 'TMXD', 'GYPE', 'NZCAZCLEP', 'YPEHZCV', 'NL']\n",
      "\n",
      "English words validation:\n",
      "[('ALCETNFWLC', False), ('APCTZO', False), ('ZQ', False), ('QWLVTYPDD', False), ('ZY', False), ('TMXD', False), ('GYPE', True), ('NZCAZCLEP', False), ('YPEHZCV', False), ('NL', False)]\n",
      "Fractional valid English word: 0.07692307692307693\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 3\n",
      "[\"ZKBDSMEVKB ZOBSYN YP PVKUSXOCC YX SLW'C FXOD MYBZYBKDO XODGYBU MK.\", '1988; LED DROBO KBO SXNOZOXNOXD BOZYBDC YP DRO DOBW PBYW OVCOGROBO.', '_________________________________________________________________', '', 'XYNO:XZ-, XOHD:[9529]XBYPP, ZBOFSYEC:[9530]XYDGYBU, EZ:[9531]= X =']\n",
      "\n",
      "Tokenized words:\n",
      "['ZKBDSMEVKB', 'ZOBSYN', 'YP', 'PVKUSXOCC', 'YX', 'SLWC', 'FXOD', 'MYBZYBKDO', 'XODGYBU', 'MK']\n",
      "\n",
      "English words validation:\n",
      "[('ZKBDSMEVKB', False), ('ZOBSYN', False), ('YP', False), ('PVKUSXOCC', False), ('YX', False), ('SLWC', False), ('FXOD', False), ('MYBZYBKDO', False), ('XODGYBU', False), ('MK', False)]\n",
      "Fractional valid English word: 0.07692307692307693\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 4\n",
      "[\"YJACRLDUJA YNARXM XO OUJTRWNBB XW RKV'B EWNC LXAYXAJCN WNCFXAT LJ.\", '1988; KDC CQNAN JAN RWMNYNWMNWC ANYXACB XO CQN CNAV OAXV NUBNFQNAN.', '_________________________________________________________________', '', 'WXMN:WY-, WNGC:[9529]WAXOO, YANERXDB:[9530]WXCFXAT, DY:[9531]= W =']\n",
      "\n",
      "Tokenized words:\n",
      "['YJACRLDUJA', 'YNARXM', 'XO', 'OUJTRWNBB', 'XW', 'RKVB', 'EWNC', 'LXAYXAJCN', 'WNCFXAT', 'LJ']\n",
      "\n",
      "English words validation:\n",
      "[('YJACRLDUJA', False), ('YNARXM', False), ('XO', False), ('OUJTRWNBB', False), ('XW', False), ('RKVB', False), ('EWNC', False), ('LXAYXAJCN', False), ('WNCFXAT', False), ('LJ', False)]\n",
      "Fractional valid English word: 0.038461538461538464\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 5\n",
      "[\"XIZBQKCTIZ XMZQWL WN NTISQVMAA WV QJU'A DVMB KWZXWZIBM VMBEWZS KI.\", '1988; JCB BPMZM IZM QVLMXMVLMVB ZMXWZBA WN BPM BMZU NZWU MTAMEPMZM.', '_________________________________________________________________', '', 'VWLM:VX-, VMFB:[9529]VZWNN, XZMDQWCA:[9530]VWBEWZS, CX:[9531]= V =']\n",
      "\n",
      "Tokenized words:\n",
      "['XIZBQKCTIZ', 'XMZQWL', 'WN', 'NTISQVMAA', 'WV', 'QJUA', 'DVMB', 'KWZXWZIBM', 'VMBEWZS', 'KI']\n",
      "\n",
      "English words validation:\n",
      "[('XIZBQKCTIZ', False), ('XMZQWL', False), ('WN', False), ('NTISQVMAA', False), ('WV', False), ('QJUA', False), ('DVMB', False), ('KWZXWZIBM', False), ('VMBEWZS', False), ('KI', False)]\n",
      "Fractional valid English word: 0.038461538461538464\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 6\n",
      "[\"WHYAPJBSHY WLYPVK VM MSHRPULZZ VU PIT'Z CULA JVYWVYHAL ULADVYR JH.\", '1988; IBA AOLYL HYL PUKLWLUKLUA YLWVYAZ VM AOL ALYT MYVT LSZLDOLYL.', '_________________________________________________________________', '', 'UVKL:UW-, ULEA:[9529]UYVMM, WYLCPVBZ:[9530]UVADVYR, BW:[9531]= U =']\n",
      "\n",
      "Tokenized words:\n",
      "['WHYAPJBSHY', 'WLYPVK', 'VM', 'MSHRPULZZ', 'VU', 'PITZ', 'CULA', 'JVYWVYHAL', 'ULADVYR', 'JH']\n",
      "\n",
      "English words validation:\n",
      "[('WHYAPJBSHY', False), ('WLYPVK', False), ('VM', False), ('MSHRPULZZ', False), ('VU', False), ('PITZ', False), ('CULA', False), ('JVYWVYHAL', False), ('ULADVYR', False), ('JH', False)]\n",
      "Fractional valid English word: 0.07692307692307693\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 7\n",
      "[\"VGXZOIARGX VKXOUJ UL LRGQOTKYY UT OHS'Y BTKZ IUXVUXGZK TKZCUXQ IG.\", '1988; HAZ ZNKXK GXK OTJKVKTJKTZ XKVUXZY UL ZNK ZKXS LXUS KRYKCNKXK.', '_________________________________________________________________', '', 'TUJK:TV-, TKDZ:[9529]TXULL, VXKBOUAY:[9530]TUZCUXQ, AV:[9531]= T =']\n",
      "\n",
      "Tokenized words:\n",
      "['VGXZOIARGX', 'VKXOUJ', 'UL', 'LRGQOTKYY', 'UT', 'OHSY', 'BTKZ', 'IUXVUXGZK', 'TKZCUXQ', 'IG']\n",
      "\n",
      "English words validation:\n",
      "[('VGXZOIARGX', False), ('VKXOUJ', False), ('UL', False), ('LRGQOTKYY', False), ('UT', True), ('OHSY', False), ('BTKZ', False), ('IUXVUXGZK', False), ('TKZCUXQ', False), ('IG', False)]\n",
      "Fractional valid English word: 0.07692307692307693\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 8\n",
      "[\"UFWYNHZQFW UJWNTI TK KQFPNSJXX TS NGR'X ASJY HTWUTWFYJ SJYBTWP HF.\", '1988; GZY YMJWJ FWJ NSIJUJSIJSY WJUTWYX TK YMJ YJWR KWTR JQXJBMJWJ.', '_________________________________________________________________', '', 'STIJ:SU-, SJCY:[9529]SWTKK, UWJANTZX:[9530]STYBTWP, ZU:[9531]= S =']\n",
      "\n",
      "Tokenized words:\n",
      "['UFWYNHZQFW', 'UJWNTI', 'TK', 'KQFPNSJXX', 'TS', 'NGRX', 'ASJY', 'HTWUTWFYJ', 'SJYBTWP', 'HF']\n",
      "\n",
      "English words validation:\n",
      "[('UFWYNHZQFW', False), ('UJWNTI', False), ('TK', False), ('KQFPNSJXX', False), ('TS', False), ('NGRX', False), ('ASJY', False), ('HTWUTWFYJ', False), ('SJYBTWP', False), ('HF', False)]\n",
      "Fractional valid English word: 0.038461538461538464\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 9\n",
      "[\"TEVXMGYPEV TIVMSH SJ JPEOMRIWW SR MFQ'W ZRIX GSVTSVEXI RIXASVO GE.\", '1988; FYX XLIVI EVI MRHITIRHIRX VITSVXW SJ XLI XIVQ JVSQ IPWIALIVI.', '_________________________________________________________________', '', 'RSHI:RT-, RIBX:[9529]RVSJJ, TVIZMSYW:[9530]RSXASVO, YT:[9531]= R =']\n",
      "\n",
      "Tokenized words:\n",
      "['TEVXMGYPEV', 'TIVMSH', 'SJ', 'JPEOMRIWW', 'SR', 'MFQW', 'ZRIX', 'GSVTSVEXI', 'RIXASVO', 'GE']\n",
      "\n",
      "English words validation:\n",
      "[('TEVXMGYPEV', False), ('TIVMSH', False), ('SJ', False), ('JPEOMRIWW', False), ('SR', False), ('MFQW', False), ('ZRIX', False), ('GSVTSVEXI', False), ('RIXASVO', False), ('GE', True)]\n",
      "Fractional valid English word: 0.07692307692307693\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 10\n",
      "[\"SDUWLFXODU SHULRG RI IODNLQHVV RQ LEP'V YQHW FRUSRUDWH QHWZRUN FD.\", '1988; EXW WKHUH DUH LQGHSHQGHQW UHSRUWV RI WKH WHUP IURP HOVHZKHUH.', '_________________________________________________________________', '', 'QRGH:QS-, QHAW:[9529]QURII, SUHYLRXV:[9530]QRWZRUN, XS:[9531]= Q =']\n",
      "\n",
      "Tokenized words:\n",
      "['SDUWLFXODU', 'SHULRG', 'RI', 'IODNLQHVV', 'RQ', 'LEPV', 'YQHW', 'FRUSRUDWH', 'QHWZRUN', 'FD']\n",
      "\n",
      "English words validation:\n",
      "[('SDUWLFXODU', False), ('SHULRG', False), ('RI', False), ('IODNLQHVV', False), ('RQ', False), ('LEPV', False), ('YQHW', False), ('FRUSRUDWH', False), ('QHWZRUN', False), ('FD', False)]\n",
      "Fractional valid English word: 0.07692307692307693\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 11\n",
      "[\"RCTVKEWNCT RGTKQF QH HNCMKPGUU QP KDO'U XPGV EQTRQTCVG PGVYQTM EC.\", '1988; DWV VJGTG CTG KPFGRGPFGPV TGRQTVU QH VJG VGTO HTQO GNUGYJGTG.', '_________________________________________________________________', '', 'PQFG:PR-, PGZV:[9529]PTQHH, RTGXKQWU:[9530]PQVYQTM, WR:[9531]= P =']\n",
      "\n",
      "Tokenized words:\n",
      "['RCTVKEWNCT', 'RGTKQF', 'QH', 'HNCMKPGUU', 'QP', 'KDOU', 'XPGV', 'EQTRQTCVG', 'PGVYQTM', 'EC']\n",
      "\n",
      "English words validation:\n",
      "[('RCTVKEWNCT', False), ('RGTKQF', False), ('QH', False), ('HNCMKPGUU', False), ('QP', False), ('KDOU', False), ('XPGV', False), ('EQTRQTCVG', False), ('PGVYQTM', False), ('EC', False)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractional valid English word: 0.038461538461538464\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 12\n",
      "[\"QBSUJDVMBS QFSJPE PG GMBLJOFTT PO JCN'T WOFU DPSQPSBUF OFUXPSL DB.\", '1988; CVU UIFSF BSF JOEFQFOEFOU SFQPSUT PG UIF UFSN GSPN FMTFXIFSF.', '_________________________________________________________________', '', 'OPEF:OQ-, OFYU:[9529]OSPGG, QSFWJPVT:[9530]OPUXPSL, VQ:[9531]= O =']\n",
      "\n",
      "Tokenized words:\n",
      "['QBSUJDVMBS', 'QFSJPE', 'PG', 'GMBLJOFTT', 'PO', 'JCNT', 'WOFU', 'DPSQPSBUF', 'OFUXPSL', 'DB']\n",
      "\n",
      "English words validation:\n",
      "[('QBSUJDVMBS', False), ('QFSJPE', False), ('PG', False), ('GMBLJOFTT', False), ('PO', True), ('JCNT', False), ('WOFU', False), ('DPSQPSBUF', False), ('OFUXPSL', False), ('DB', False)]\n",
      "Fractional valid English word: 0.07692307692307693\n",
      "\n",
      "\n",
      "\n",
      "Decryption with shift: 13\n",
      "[\"PARTICULAR PERIOD OF FLAKINESS ON IBM'S VNET CORPORATE NETWORK CA.\", '1988; BUT THERE ARE INDEPENDENT REPORTS OF THE TERM FROM ELSEWHERE.', '_________________________________________________________________', '', 'NODE:NP-, NEXT:[9529]NROFF, PREVIOUS:[9530]NOTWORK, UP:[9531]= N =']\n",
      "\n",
      "Tokenized words:\n",
      "['PARTICULAR', 'PERIOD', 'OF', 'FLAKINESS', 'ON', 'IBMS', 'VNET', 'CORPORATE', 'NETWORK', 'CA']\n",
      "\n",
      "English words validation:\n",
      "[('PARTICULAR', True), ('PERIOD', True), ('OF', True), ('FLAKINESS', True), ('ON', True), ('IBMS', False), ('VNET', False), ('CORPORATE', True), ('NETWORK', True), ('CA', True)]\n",
      "Fractional valid English word: 0.6923076923076923\n",
      "\n",
      "Hurray! the correct shift is: 13\n"
     ]
    }
   ],
   "source": [
    "valid_shift = None\n",
    "for n in range(26):\n",
    "    # Attempt to decrypt with shift n\n",
    "    rdd_decrypted = rdd_sample.map(lambda line: decrypt(line, n) )\n",
    "    \n",
    "    print('Decryption with shift:', n)\n",
    "    print( rdd_decrypted.collect() )\n",
    "    \n",
    "    # Validate English words\n",
    "    rdd_english_words = validate_english_words(rdd_decrypted)\n",
    "    \n",
    "    # Count the number of valid English words\n",
    "    english_words_count = rdd_english_words.map(lambda token: token[1]).reduce(add)\n",
    "    \n",
    "    # Proportion of valid English words\n",
    "    fraction = english_words_count / rdd_english_words.count()\n",
    "    print('Fractional valid English word:', fraction)\n",
    "    \n",
    "    if fraction > 0.5:\n",
    "        valid_shift = n\n",
    "        print('\\nHurray! the correct shift is:', valid_shift)\n",
    "        break\n",
    "    \n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the decrypted text to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid shift: 13\n"
     ]
    }
   ],
   "source": [
    "print('Valid shift:', valid_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_decrypted = rdd.map(lambda line: decrypt(line, valid_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_filename = 'D'+filename\n",
    "if not os.path.exists(result_filename):\n",
    "    rdd_decrypted.saveAsTextFile(result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
